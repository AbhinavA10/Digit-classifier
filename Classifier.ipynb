{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "# MNIST Digit Classification\n",
    "We will be training a CNN to classify images of handwritten digits from the MNIST dataset. Then, we will use this on our own handwritten digits.\n",
    "\n",
    "First, let's import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's keep our Tensorflow logging to a minimum\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "from IPython.display import Image \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is built into Keras. From the documentation [here](https://keras.io/api/datasets/mnist/), we can get some important info. The MNIST dataset is:\n",
    "> a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
    "\n",
    "From the [MNIST homepage](http://yann.lecun.com/exdb/mnist/),\n",
    "> The digits have been size-normalized and centered in a fixed-size image. The images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.\n",
    "\n",
    "Internally, the dataset is stored as numpy array files.\n",
    "\n",
    "The pixel values of each image range from 0 to 255, so we will have to scale it to `[0,1]` to normalize.\n",
    "\n",
    "Additionally, since the images are grayscale (single channel), we should reshape the data to have a single colour channel. Normally, images used in a CNN have 3 channels for RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1) # the shape of a single sample/image not including batchsize is (height, width, num of channels)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "#TODO maybe move image normalization to Keras Model?\n",
    "\n",
    "assert x_train.shape == (60000, 28, 28)\n",
    "assert x_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,) # a NumPy array of digit labels (0-9)\n",
    "assert y_test.shape == (10000,) # a NumPy array of digit labels (0-9)\n",
    "\n",
    "# Reshape image for single colour channel\n",
    "# Change images to have shape (28, 28, 1) instead of (28,28), by appending a dimension\n",
    "# only needed when Keras model does not use the Reshape layer\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"training samples\")\n",
    "print(x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also view some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8), dpi=80)\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(x_train[i], cmap='gray_r', interpolation='none')\n",
    "    plt.title(f\"Digit: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "Next, let's define the CNN model using Keras' sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer(input_shape=input_shape),\n",
    "        # keras.layers.Reshape(target_shape=input_shape+(1,)), # Reshape to (batch_size, 28, 28, 1),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),        \n",
    "        layers.BatchNormalization(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(100,activation='relu'),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    ")\n",
    "Image(retina=True, filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# sparse_categorical_crossentropy accepts non-o.h.e values for y_true\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping( # runs at end of every epoch\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=1e-2, # no longer improving means when \"no better than 1e-2 less\"\n",
    "        patience=2, # if no longer improving for at least 2 epochs\"\n",
    "        verbose=1,\n",
    "    ),\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=\"tensorboard_logs\",\n",
    "        histogram_freq=1,  # log histogram visualizations once per epoch\n",
    "        update_freq=\"epoch\",  # write logs once per epoch\n",
    "    )\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load tensorboard, to view live plots as our model trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view tensorboard within this notebook, uncomment the following section:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tensorboard_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, training the model for 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2 # 15\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, \n",
    "                        callbacks=callbacks,validation_split=0.1)\n",
    "model.save('saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the training history to a dataframe\n",
    "history_df = pd.DataFrame(history.history)\n",
    "# Pandas built-in methods to quickly plot the data\n",
    "# history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "# history_df.loc[:, ['accuracy', 'val_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the metrics\n",
    "fig = plt.figure(figsize=(8, 8), dpi=80)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "print(\"Generate predictions for test samples\")\n",
    "predictions = model.predict(x_test)\n",
    "print(\"predictions shape (samples, probabilities):\", predictions.shape)\n",
    "predictions[0] # each entry in predictions tensor has a list of probabilities of the digit being 0,1,...9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check if a single prediction matches the ground truth in this way:\n",
    "print(np.argmax(predictions[0]))\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function from https://www.tensorflow.org/tutorials/keras/classification#verify_predictions\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    true_label, img = true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "  \n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "  \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "      color = 'blue'\n",
    "    else:\n",
    "      color = 'red'\n",
    "  \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n",
    "                                100*np.max(predictions_array),\n",
    "                                true_label),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    true_label = true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "  \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], y_test, x_test)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions[i], y_test, x_test)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, predictions[i], y_test)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the trained model on a single test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab an image from the test dataset.\n",
    "img = x_test[1]\n",
    "print(img.shape)\n",
    "\n",
    "# Add the image to a batch where it's the only member, by reshaping\n",
    "# tf.keras models make predictions on a batch of samples at once.\n",
    "img = (np.expand_dims(img,0))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_single = model.predict(img)\n",
    "plot_value_array(1, predictions_single[0], y_test)\n",
    "np.argmax(predictions_single[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: use model.predict() on our own image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
